{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20a7888f",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5043ef4",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Pratham Dhiman/AppData/Local/Microsoft/WindowsApps/python3.11.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow pandas matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b841bc4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "(1,10): error CS1002: ; expected\r\n(2,15): error CS1002: ; expected\r\n(2,15): error CS1525: Invalid expression term 'as'\r\n(2,20): error CS1002: ; expected\r\n(3,19): error CS1002: ; expected\r\n(3,19): error CS1525: Invalid expression term 'as'\r\n(3,24): error CS1002: ; expected\r\n(4,14): error CS1002: ; expected\r\n(4,14): error CS1525: Invalid expression term 'as'",
     "output_type": "error",
     "traceback": [
      "(1,10): error CS1002: ; expected\r\n",
      "(2,15): error CS1002: ; expected\r\n",
      "(2,15): error CS1525: Invalid expression term 'as'\r\n",
      "(2,20): error CS1002: ; expected\r\n",
      "(3,19): error CS1002: ; expected\r\n",
      "(3,19): error CS1525: Invalid expression term 'as'\r\n",
      "(3,24): error CS1002: ; expected\r\n",
      "(4,14): error CS1002: ; expected\r\n",
      "(4,14): error CS1525: Invalid expression term 'as'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2141b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(\"jigsaw-toxic-comment-classification-challenge\" , \"train.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78e38a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be53d545",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[5]['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e38de27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.columns[2:]].iloc[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fc2235",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a72f72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401ffaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['comment_text']\n",
    "y = df[df.columns[2:]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f812994",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 200000 # number of words in the vcab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a2bd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TextVectorization(max_tokens = MAX_FEATURES , output_sequence_length=1800,output_mode='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d03844",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.adapt(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227b381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_text = vectorizer(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c0dff1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36efd3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((vectorized_text , y))\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(160000)\n",
    "dataset = dataset.batch(16)\n",
    "dataset = dataset.prefetch(8)\n",
    "\n",
    "# MCSHBAP - map,cache , shuffle, batch , prefetch     from_tensor_slices , list_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a7eab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X , batch_y = dataset.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551cf11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb16de68",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e85dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset.take(int(len(dataset)*.7))\n",
    "val = dataset.skip(int(len(dataset)*0.7)).take(int(len(dataset) * 0.2))\n",
    "test = dataset.skip(int(len(dataset) * 0.9)).take(int(len(dataset) * 0.1 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4830d5",
   "metadata": {},
   "source": [
    "## Create Deep neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac8ae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM , Dropout , Bidirectional,Dense , Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08c2b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d4a109",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(MAX_FEATURES+1 , 32 , input_shape=(1800,)))\n",
    "model.add(Bidirectional(LSTM(32 , activation = 'tanh')))\n",
    "\n",
    "model.add(Dense(128 , activation = 'relu'))\n",
    "model.add(Dense(256 , activation = 'relu'))\n",
    "model.add(Dense(128 , activation = 'relu'))\n",
    "model.add(Dense(6 , activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6151ac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='BinaryCrossentropy',  # Suitable for multi-label classification\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760ecfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1333e4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train , epochs = 1,validation_data = val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eca8d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fdd141",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b016df",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327cf8d0",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bc02c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = vectorizer('You freaking suck! I am going to hit you.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ede2998",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d8521b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(res > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abb1af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X, batch_y = test.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7860f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(model.predict(batch_X) > 0.5).astype(int)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dd0972",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153b90bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb1e673",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b966aa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test.as_numpy_iterator(): \n",
    "    # Unpack the batch \n",
    "    X_true, y_true = batch\n",
    "    # Make a prediction \n",
    "    yhat = model.predict(X_true)\n",
    "    \n",
    "    # Flatten the predictions\n",
    "    y_true = y_true.flatten()\n",
    "    yhat = yhat.flatten()\n",
    "    \n",
    "    pre.update_state(y_true, yhat)\n",
    "    re.update_state(y_true, yhat)\n",
    "    acc.update_state(y_true, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071ef2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Precision: {pre.result().numpy()}, Recall:{re.result().numpy()}, Accuracy:{acc.result().numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a1b145",
   "metadata": {},
   "source": [
    "##  Test and Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcf9f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4180e582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import gradio as gr\n",
    "\n",
    "model.save('toxicity.h5')\n",
    "\n",
    "model = tf.keras.models.load_model('toxicity.h5')\n",
    "\n",
    "input_str = vectorizer('hey i freaken hate you!')\n",
    "\n",
    "\n",
    "res = model.predict(np.expand_dims(input_str,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55187bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01555cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_comment(comment):\n",
    "    vectorized_comment = vectorizer([comment])\n",
    "    results = model.predict(vectorized_comment)\n",
    "    \n",
    "    text = ''\n",
    "    for idx, col in enumerate(df.columns[2:]):\n",
    "        text += '{}: {}\\n'.format(col, results[0][idx]>0.5)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c22ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "interface = gr.Interface(fn=score_comment, \n",
    "                         inputs=gr.inputs.Textbox(lines=2, placeholder='Comment to score'),\n",
    "                        outputs='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665737c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "interface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
